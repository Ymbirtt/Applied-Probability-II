\documentclass{article}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{fancyhdr}
\usepackage{semantic}
\usepackage[noload]{qtree}
\usepackage{comment}
\usepackage{pdflscape}
\usepackage{graphicx}
\usepackage[margin=1in]{geometry}
\usepackage{moreverb}
\usepackage{caption}
\usepackage{url}

\begin{document}
%I don't even use half of this crap...
\newcommand{\nl}{\mbox{}\\} % force newline
\newcommand{\altx}{\:|\:} % bnf alternative on same line
\newcommand{\alty}{\\[0.1cm]&\:|\:&} % bnf alternative on new line
\newcommand{\minus}{\mbox{-}} % minus sign
\newcommand{\term}[1]{\,\mbox{\tt #1}\,} % bnf terminal
\newcommand{\str}{\stackrel{.}{\rightsquigarrow}} % one-step structural semantics
\newcommand{\sts}{\stackrel{_{*}}{\rightsquigarrow}} % multi-step structural semantics
\newcommand{\nat}{\rightsquigarrow} % natural semantics
\newcommand{\axm}[4]{\item[{\sc #1 : }]\begin{tabular}{cc}#2\\\hline#3\\\end{tabular}\quad#4}
\newcommand{\sem}[1]{[\![#1]\!]}
\newcommand{\lam}[2]{\lambda {#1} \,.\, #2}
\newcommand{\lfp}[1]{lfp\,(\,#1\,)}
\newcommand{\fix}[1]{fix\,(\,#1\,)}
\newcommand{\hoarep}[3]{\{#1\}\,#2\,\{#3\}}
\newcommand{\hoareP}[3]{\left\{\begin{array}{c}#1\end{array}\right\}\,#2\,\newline\left\{\begin{array}{c}#3\end{array}\right\}}
\newcommand{\hoaret}[3]{[#1]\,#2\,[#3]}
\newcommand{\hoareT}[3]{\left[\begin{array}{c}#1\end{array}\right]\,#2\,\left[\begin{array}{c}#3\end{array}\right]}
\newcommand{\assume}[1]{$\blacklozenge$ #1}
\newcommand{\st}{\,\; st \,\;}
%\newcommand{\iff}{\Rightleftarrow}
%\newcommand{\implies}{\Rightarrow}

\begin{center}
	\Huge{CAVEAT LECTOR:}
\end{center}
\begin{center}
	\Large{THIS DOCUMENT CONTAINS ERRORS}
\end{center}

Like, seriously, loads of them. No I do not know where they are. These attempts at solutions are in no way guaranteed to be accurate. Please do not read this and assume that you're totally correct/incorrect just because you agree/disagree with the stuff that's written in the big shiny \LaTeX \,document. Rather, think as you read through it. Follow my logic, and if it doesn't make sense to you then ask me. Email me\footnotetext[1]{\url{ymbirtt@gmail.com}}\footnotemark[1], grab me on Steam, Skype, League of Legends\footnotetext[2]{Ymbirtt on all}\footnotemark[2], facebook, bang on my front door repeatedly\footnotetext[3]{Bring cake}\footnotemark[3], just ask if something doesn't make sense, because I can and do make errors.

Of course, if you know what the error is and how to fix it, then feel free to write up an alternative solution of your own, or even an entire solution to a problem that I haven't yet attempted. I'll be happy to include it and give you credit for writing it. Either write it on paper, scan it to me, and email me\footnotemark[1], or for bonus points send me correct \LaTeX\, that I can just copy paste in, or for super bonus points, fork me on github\footnotetext[4]{\url{https://github.com/Ymbirtt/Applied-Probability-II}}\footnotemark[4] and push a revision at me.

Right, now that that's all out of the way, let's do some maths.

\clearpage
\section*{2011 paper}
\begin{enumerate}
\item
\begin{enumerate}
\item
Let $X_i$ denote the number of descendents of child $i$ from generation $j-1$. This gives us that

$$
N_j = X_1 + \dots + X_{N_j-1}
$$

Where $K$ is a non-negative integer valued random variable, $\{Y_i\}$ is a sequence of independent identically distributed random variables, $Z=Y_1+\dots+Y_K$ is their sum, and $G_Z(s)$ is the probability generating function for $Z$, similarly for $K$ and $Y$, we have that
$$
G_Z(s) = G_N(G_Y(s))
$$
In this question, 
$$
N_j=\sum^{N_j-1}_{i=1}X_j
$$
Each $X_j$ is the number of offspring produced by a single parent, each distributed identically to $N_1$, so
$$
G_j(s) = G_{j-1}(G_1(s))
$$
\begin{enumerate}
\item 
If a generation has no children, then the next generation will also be childless, so,
$$
N_j=0 \rightarrow N_{j+1}=0
$$
Eventual extinction corresponds to 
$$
\{\exists n \in \mathbb{N} \;\, st \;\, N_j=0\} = \bigcup^\infty_{j=1}\{N_j=0\}
$$
By continuity of probability, for any decreasing sequence of events such that $A_j \subseteq A_{j+1}$, we have that
$$
\mathbb{P}(\bigcup^\infty_{j=1}A_j) = \lim_{j\rightarrow\infty} \mathbb{P}(A_j)
$$
So, finally,
$$
e=\mathbb{P}(\bigcup^\infty_{j=1}\{N_j=0\}) = \lim_{j\rightarrow\infty} \mathbb{P}(N_j=0) = \lim_{j\rightarrow\infty}e_j
$$
$$
e=\lim_{j\rightarrow\infty}e_j
$$
\item
$G_X(s) = \sum\limits_{x \in \mathcal{X}}\mathbb{P}(X=i)s^i$, so, $G_X(0) = \mathbb{P}(X=0)$. We also have that $G_j(G_1(s)) = G_1(G_j(s))$.
\begin{align*}
e &= lim_{j\rightarrow\infty}G_j(0)\\
&= lim_{j\rightarrow\infty}G_1(G_{j-1}(0))\mbox{\;\; by continuity of G}\\
&= G_1(lim_{j\rightarrow\infty}G_{j-1}(0))\\
&= G_1(e)
\end{align*}
So $e = G_1(e)$.
\end{enumerate}
\item
\begin{enumerate}
\item
\begin{align*}
\mathbb{E}(X) &= \frac{d}{ds}G_X(s)|_{s=0}\\
\\
G_j(s) &= G_{j-1}(G(s))\\
\mathbb{E}(N_j) &= \frac{d}{ds}G_j(s)|_{s=0}\\
&= \frac{d}{ds}G_{j-1}(G_1(s))|_{s=0}\\
&= G_1'(s)G_{j-1}'(G_1(s))|_{s=0}\\
&= \mu G_{j-1}'(G_1(0)) \\
&= \mu G_{j-1}'(0) \mbox{\; \; since $G_1(0)=\mathbb{P}(X_1=0) = 0$} \\
&= \mu \mathbb{E}(N_{j-i})
\end{align*}
So, $\mathbb{E}(N_1) = \mu$ and $\mathbb{E}(N_j) = \mu \mathbb{E}(N_{j-1})$. Induction will then give us that $\mathbb{E}(N_j) = \mu^j$.
\end{enumerate}

\end{enumerate}
\clearpage
\item
\begin{enumerate}
\item
A continuous time counting process with stationary, independent increments, where the number of increments in time $t$ follows a $Po(\lambda t)$ distribution.
\item
\begin{align*}
p_n(t+h) &= \mathbb{P}(N(t+n)=n | N(t) = n-1)\mathbb{P}(N(t)=n-1) + \mathbb{P}(N(t+n)=n | N(t) = n)\mathbb{P}(N(t)=n) + o(h) \\
&= (1-\lambda h +o(h))p_n(t) + (\lambda h + o(h))p_{n-1}(t) + o(h)\\
&= p_n(t) -\lambda h p_n(t) + \lambda h p_{n-1}(t) + o(h)\\
&\implies \frac{p_n(t+h)-p_n(t)}{h} = -\lambda(p_n(t)-p_{n-1}(t))\\
&\implies p_n'(t) = -\lambda(p_n(t)-p_{n-1}(t)
\end{align*}
Where $N(t) \sim  Po(\lambda t)$, $\mathbb{P}(N(t)=n) = \frac{e^{-\lambda t}(\lambda t)^n}{n!}$, so
\begin{align*}
p_n'(t) &= \frac{d}{dt} \frac{e^{-\lambda t}(\lambda t)^n}{n!}\\
&= \frac{-\lambda e^{-\lambda t}(\lambda t)^n + n \lambda e^{-\lambda t}(\lambda t)^{n-1}}{n!}\\
&= -\lambda \left( \frac{e^{-\lambda t}(\lambda t)^n}{n!} - \frac{e^{-\lambda t}(\lambda t)^{n-1}}{(n-1)!}\right)\\
&= -\lambda(p_n(t) - p_{n-1}(t))
\end{align*}
And, where $n=0$, $p_{-1}(t) = 0$, so 
$$
p_0'(t) = -\lambda p_0(t)
$$
\end{enumerate}

\end{enumerate}


\end{document}